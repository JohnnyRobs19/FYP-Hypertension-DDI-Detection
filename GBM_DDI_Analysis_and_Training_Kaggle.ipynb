{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14203872,"sourceType":"datasetVersion","datasetId":9059048}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Gradient Boosting Machine (GBM) DDI Analysis and Training - Sequential Ensemble Learning\n\n## ğŸ¯ Purpose: Sequential Ensemble Learning for Drug-Drug Interaction Prediction\n\nThis notebook implements **Gradient Boosting Machine (GBM)** classifier for predicting drug-drug interaction severity.\n\n---\n\n## ğŸ“‹ Notebook Structure\n\n### **Part 1: Model Training & Evaluation (Cells 0-44)**\n1. Setup and Data Loading\n2. Data Exploration and Quality Check\n3. Feature Engineering\n4. Train-Test Split (80/20, stratified)\n5. **Enhanced GridSearchCV Hyperparameter Optimization**\n6. Model Training with optimal parameters\n7. Performance Evaluation\n8. Cross-Validation Analysis\n\n### **Part 2: Knowledge-Driven XAI Clinical Decision Support (Cells 45-63)**\n9. XAI Framework Integration\n10. Clinical Scenarios Analysis\n11. Safer Medication Pathway Recommendations\n\n---\n\n## ğŸ”¬ GBM Key Characteristics\n\n**Strengths:**\n- Optimizes differentiable loss function directly\n- Sequential ensemble of decision trees\n- Powerful for capturing complex interactions\n- Reduced bias through iterative error correction\n- Excellent for multi-class classification\n\n**Enhanced Hyperparameters Optimized:**\n- `n_estimators`: Number of boosting stages (100-500)\n- `learning_rate`: Learning rate/shrinkage (0.01-0.3)\n- `max_depth`: Maximum tree depth (3-7)\n- `subsample`: Fraction of samples per iteration (0.6-1.0)\n- `max_features`: Features per tree ('sqrt', 'log2')\n- `min_samples_split`: Tree complexity control\n- `min_samples_leaf`: Leaf node complexity control\n\n**Performance Targets:**\n- âœ… Target: 90-95% accuracy\n- âœ… Match GBM/Random Forest performance\n- âœ… Perfect detection of Major interactions\n\n---","metadata":{}},{"cell_type":"markdown","source":"# Part 1: Setup and Data Loading\n\n## Step 1: Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# GBM\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n# Machine Learning\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import (\n    classification_report,\n    confusion_matrix,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    ConfusionMatrixDisplay\n)\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Configure plotting\nplt.style.use('default')\nsns.set_palette(\"husl\")\n\nprint(\"âœ“ Libraries imported successfully\")\nprint(\"âœ“ GradientBoostingClassifier imported\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 2: Load Dataset","metadata":{}},{"cell_type":"code","source":"# Load the dataset (KAGGLE EDITION - Updated path)\ndf = pd.read_csv('/kaggle/input/fyp-drug-interaction-final/FYP_Drug_Interaction_Final.csv')\n\nprint(\"=\"*80)\nprint(\"DATASET OVERVIEW (KAGGLE EDITION)\")\nprint(\"=\"*80)\nprint(f\"\\nTotal drug pairs: {len(df)}\")\nprint(f\"Columns: {list(df.columns)}\")\nprint(f\"\\nFirst few rows:\")\ndf.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 3: Data Exploration and Quality Check","metadata":{}},{"cell_type":"code","source":"print(\"=\"*80)\nprint(\"DATA QUALITY CHECK\")\nprint(\"=\"*80)\n\n# Check for missing values\nprint(\"\\nMissing values in Final_Severity:\")\nprint(df['Final_Severity'].isna().sum())\n\n# Check class distribution BEFORE filtering\nprint(\"\\nClass distribution (before filtering):\")\nprint(df['Final_Severity'].value_counts(dropna=False))\n\n# Filter out rows without Final_Severity\ndf_valid = df.dropna(subset=['Final_Severity'])\nprint(f\"\\nâœ“ Rows with valid Final_Severity: {len(df_valid)}\")\nprint(f\"âœ“ Rows filtered out: {len(df) - len(df_valid)}\")\n\n# Check class distribution AFTER filtering\nprint(\"\\nFinal class distribution:\")\nclass_dist = df_valid['Final_Severity'].value_counts().sort_index()\nprint(class_dist)\nprint(f\"\\nClass imbalance ratio:\")\nfor severity in class_dist.index:\n    print(f\"  {severity}: {class_dist[severity]/len(df_valid)*100:.1f}%\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 4: Visualize Class Distribution\n\n**Critical for GBM:** Understanding class imbalance is essential because GBM excels at handling imbalanced datasets through:\n- `scale_pos_weight` parameter\n- Focused error correction on minority class\n- Sample weighting","metadata":{}},{"cell_type":"code","source":"# Visualize class distribution\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Bar plot\nclass_counts = df_valid['Final_Severity'].value_counts().sort_index()\naxes[0].bar(class_counts.index, class_counts.values, color=['#d62728', '#ff7f0e', '#2ca02c'])\naxes[0].set_xlabel('Severity Level', fontsize=12, fontweight='bold')\naxes[0].set_ylabel('Number of Drug Pairs', fontsize=12, fontweight='bold')\naxes[0].set_title('Distribution of DDI Severity Levels', fontsize=14, fontweight='bold')\naxes[0].grid(axis='y', alpha=0.3)\n\n# Add value labels on bars\nfor i, (severity, count) in enumerate(class_counts.items()):\n    axes[0].text(i, count + 2, str(count), ha='center', fontweight='bold')\n\n# Pie chart\ncolors = ['#d62728', '#ff7f0e', '#2ca02c']\naxes[1].pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%',\n            colors=colors, startangle=90)\naxes[1].set_title('Severity Distribution (Percentage)', fontsize=14, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n# Calculate imbalance ratio for GBM weighting\nmajor_count = class_counts.get('Major', 0)\nother_count = class_counts.sum() - major_count\nimbalance_ratio = other_count / major_count if major_count > 0 else 1\nprint(f\"\\nğŸ“Š Class Imbalance Analysis:\")\nprint(f\"   Major class: {major_count} samples ({major_count/len(df_valid)*100:.1f}%)\")\nprint(f\"   Other classes: {other_count} samples ({other_count/len(df_valid)*100:.1f}%)\")\nprint(f\"   Imbalance ratio: {imbalance_ratio:.2f}:1\")\nprint(f\"   âœ“ GBM will use scale_pos_weight to handle imbalance\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 5: Drug Class Analysis","metadata":{}},{"cell_type":"code","source":"print(\"=\"*80)\nprint(\"DRUG CLASS ANALYSIS\")\nprint(\"=\"*80)\n\n# Analyze drug classes\nprint(\"\\nDrug A classes:\")\nprint(df_valid['Drug_A_Class'].value_counts())\nprint(\"\\nDrug B classes:\")\nprint(df_valid['Drug_B_Class'].value_counts())\n\n# Visualize drug class combinations\nfig, ax = plt.subplots(figsize=(12, 6))\nclass_combos = df_valid.groupby(['Drug_A_Class', 'Drug_B_Class']).size().sort_values(ascending=False)\nclass_combos.head(15).plot(kind='barh', ax=ax, color='steelblue')\nax.set_xlabel('Number of Drug Pairs', fontsize=12, fontweight='bold')\nax.set_ylabel('Drug Class Combination', fontsize=12, fontweight='bold')\nax.set_title('Top 15 Drug Class Combinations', fontsize=14, fontweight='bold')\nax.grid(axis='x', alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Severity distribution\nseverity_counts = df_valid['Final_Severity'].value_counts().sort_index()\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"DDI SEVERITY DISTRIBUTION\")\nprint(\"=\"*80)\nfor severity, count in severity_counts.items():\n    percentage = count / len(df_valid) * 100\n    print(f\"{severity:12s}: {count:3d} pairs ({percentage:5.1f}%)\")\nprint(f\"{'Total':12s}: {len(df_valid):3d} pairs (100.0%)\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Beautiful visualization of severity distribution\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n\n# Bar chart\ncolors = {'Major': '#d62728', 'Moderate': '#ff7f0e', 'Minor': '#2ca02c', 'None': '#1f77b4'}\nseverity_colors = [colors.get(sev, '#7f7f7f') for sev in severity_counts.index]\n\nbars = ax1.bar(severity_counts.index, severity_counts.values, color=severity_colors, edgecolor='black', linewidth=1.5)\nfor i, (bar, value) in enumerate(zip(bars, severity_counts.values)):\n    percentage = value / len(df_valid) * 100\n    ax1.text(bar.get_x() + bar.get_width()/2, value + 3, \n             f'{value}\\n({percentage:.1f}%)', \n             ha='center', va='bottom', fontweight='bold', fontsize=11)\n\nax1.set_ylabel('Number of Drug Pairs', fontsize=12, fontweight='bold')\nax1.set_xlabel('DDI Severity Level', fontsize=12, fontweight='bold')\nax1.set_title('DDI Severity Distribution (Bar Chart)', fontsize=14, fontweight='bold')\nax1.grid(axis='y', alpha=0.3)\n\n# Pie chart\nwedges, texts, autotexts = ax2.pie(\n    severity_counts.values, \n    labels=severity_counts.index,\n    autopct='%1.1f%%',\n    colors=severity_colors,\n    startangle=90,\n    explode=[0.05 if sev == 'Major' else 0 for sev in severity_counts.index],\n    textprops={'fontsize': 11, 'fontweight': 'bold'}\n)\n\nax2.set_title('DDI Severity Distribution (Pie Chart)', fontsize=14, fontweight='bold')\n\nplt.tight_layout()\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 4. Drug Class Interaction Patterns","metadata":{}},{"cell_type":"code","source":"# Analyze interactions by drug class combinations\nclass_interactions = df_valid.groupby(['Drug_A_Class', 'Drug_B_Class', 'Final_Severity']).size().reset_index(name='Count')\n\nprint(\"=\"*80)\nprint(\"DRUG CLASS INTERACTION PATTERNS\")\nprint(\"=\"*80)\nprint(\"\\nTop 10 most common class-severity combinations:\")\nprint(class_interactions.nlargest(10, 'Count')[['Drug_A_Class', 'Drug_B_Class', 'Final_Severity', 'Count']].to_string(index=False))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create interaction heatmap\ninteraction_matrix = df_valid.groupby(['Drug_A_Class', 'Drug_B_Class']).size().unstack(fill_value=0)\n\n# Make symmetric\nfor idx in interaction_matrix.index:\n    for col in interaction_matrix.columns:\n        if idx != col:\n            total = interaction_matrix.loc[idx, col] + interaction_matrix.loc[col, idx]\n            interaction_matrix.loc[idx, col] = total\n            interaction_matrix.loc[col, idx] = total\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(interaction_matrix, annot=True, fmt='d', cmap='YlOrRd', \n            linewidths=0.5, cbar_kws={'label': 'Number of Interactions'})\nplt.title('Drug Class Interaction Heatmap', fontsize=14, fontweight='bold', pad=20)\nplt.xlabel('Drug Class B', fontsize=12, fontweight='bold')\nplt.ylabel('Drug Class A', fontsize=12, fontweight='bold')\nplt.tight_layout()\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 5. Feature Engineering","metadata":{}},{"cell_type":"code","source":"print(\"=\"*80)\nprint(\"FEATURE ENGINEERING\")\nprint(\"=\"*80)\n\n# Select features for modeling\nfeatures = ['Drug_A_Name', 'Drug_B_Name', 'Drug_A_Class', 'Drug_B_Class']\nprint(f\"\\nOriginal features: {features}\")\n\n# One-hot encoding\nX = pd.get_dummies(df_valid[features], drop_first=False)\nprint(f\"\\nAfter one-hot encoding: {X.shape[1]} features\")\nprint(f\"  - Binary features created from categorical variables\")\nprint(f\"  - Each drug name and class becomes a binary column\")\n\n# Encode target variable\nle = LabelEncoder()\ny = le.fit_transform(df_valid['Final_Severity'])\ntarget_classes = list(le.classes_)\n\nprint(f\"\\nTarget variable: Final_Severity (Patient Safety Ground Truth)\")\nprint(f\"  - Original categories: {target_classes}\")\nprint(f\"  - Encoded as integers: {dict(enumerate(target_classes))}\")\n\nprint(\"\\nâœ“ Feature engineering complete!\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 6. Train-Test Split","metadata":{}},{"cell_type":"code","source":"# âœ… REMOVED: 80/20 train-test split\n# Instead, we'll use full data with 10-fold cross-validation\n# This gives us more data for hyperparameter tuning and more reliable estimates\n\n# Keep full dataset for cross-validation\n# X and y are already defined from earlier cells\nprint(\"âœ… Using full dataset for cross-validation (no artificial train-test split)\")\nprint(f\"  - Total samples: {X.shape[0]}\")\nprint(f\"  - Feature count: {X.shape[1]}\")\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 7. GBM Model Training","metadata":{}},{"cell_type":"markdown","source":"## ğŸ¯ Step 3b: Hyperparameter Optimization with GridSearchCV\n\n**Why optimize GBM hyperparameters?**\n\nThe current GBM uses hyperparameters inherited from the Decision Tree (max_depth=10), which is overly restrictive. GBM's strength comes from:\n\n1. **Deep, diverse trees** - Individual trees can be complex because ensemble averaging prevents overfitting\n2. **Variance reduction** - Aggregating predictions from many trees reduces variance\n3. **Feature randomness** - `max_features` decorrelates trees for better ensemble diversity\n\n**Strategy:**\n- Remove max_depth restriction (let trees grow naturally)\n- Optimize n_estimators (number of trees)\n- Fine-tune min_samples_split and min_samples_leaf\n- Add class_weight='balanced' to handle any class imbalance\n\n**Expected outcome:** GBM should outperform single Decision Tree (target: >92% accuracy)","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# STEP 3.5: HYPERPARAMETER TUNING WITH NESTED CROSS-VALIDATION\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"HYPERPARAMETER TUNING WITH NESTED CROSS-VALIDATION\")\nprint(\"=\"*80)\nprint()\nprint(\"ğŸ¯ WHY NESTED CV?\")\nprint(\"   â€¢ Small dataset (406 samples) - need to use all data efficiently\")\nprint(\"   â€¢ OUTER LOOP (10-fold): Unbiased performance estimation\")\nprint(\"   â€¢ INNER LOOP (5-fold): Hyperparameter optimization\")\nprint(\"   â€¢ NO DATA LEAKAGE: Test folds never seen during tuning\")\nprint(\"   â€¢ FIXES OPTIMISTIC BIAS: Previous approach tuned on same data being evaluated\")\nprint()\n\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.utils.class_weight import compute_sample_weight\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score,\n    f1_score, roc_auc_score\n)\nimport time\nimport numpy as np\n\n# Define hyperparameter grid for GBM\nparam_grid = {\n    'n_estimators': [100, 200, 300], \n    'learning_rate': [0.01, 0.05, 0.1, 0.2], \n    'max_depth': [3, 5, 7, 9], \n    'min_samples_split': [2, 5, 10], \n    'min_samples_leaf': [1, 2, 4], \n    'subsample': [0.6, 0.8, 1.0]\n}\n\nprint(f\"ğŸ“Š Hyperparameter Grid for GBM:\")\nfor param_name, param_values in param_grid.items():\n    print(f\"   â€¢ {param_name}: {param_values}\")\nprint(f\"   â€¢ Total combinations: 1296\")\nprint()\n\n# Setup CV splitters\nouter_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\ninner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Storage for results\nnested_scores = {\n    'accuracy': [],\n    'precision': [],\n    'recall': [],\n    'f1': [],\n    'roc_auc': []\n}\n\nbest_params_per_fold = []\n\nprint(\"â³ Running Nested Cross-Validation...\")\nprint(f\"   Hardware: Kaggle GPU T4 x2 (4 CPU cores, 13GB RAM)\")\nprint(f\"   Training: {10 * 5 * 1296:,} models total (10 outer Ã— 5 inner Ã— 1296 combos)\")\nprint(f\"   Estimated time: 10-30 minutes\")\nprint()\n\nstart_time = time.time()\n\n# OUTER LOOP: Performance estimation\nfor fold_idx, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n    fold_start = time.time()\n\n    # Split data for this outer fold\n    X_train_outer = X.iloc[train_idx]\n    y_train_outer = y[train_idx]\n    X_test_outer = X.iloc[test_idx]\n    y_test_outer = y[test_idx]\n\n    print(f\"ğŸ“ Fold {fold_idx}/10: Training on {len(X_train_outer)} samples, testing on {len(X_test_outer)}\")\n\n    # CORRECT CLASS IMBALANCE HANDLING:\n    # GBM doesn't support class_weight parameter, so use sample_weight instead\n    sample_weights_outer = compute_sample_weight(class_weight='balanced', y=y_train_outer)\n\n    # INNER LOOP: Hyperparameter tuning via GridSearchCV\n    model_inner = GradientBoostingClassifier(random_state=42)\n\n    grid_search = GridSearchCV(\n        estimator=model_inner,\n        param_grid=param_grid,\n        cv=inner_cv,\n        scoring='accuracy',\n        verbose=0,\n        n_jobs=-1   # Use all 4 CPU cores on T4 x2\n    )\n\n    # Fit with sample weights (CRITICAL for class imbalance)\n    print(f\"   âš™ï¸  Running GridSearchCV with 1,296 combinations...\")\n    grid_search.fit(X_train_outer, y_train_outer, sample_weight=sample_weights_outer)\n\n    # Get best model from inner CV\n    best_model = grid_search.best_estimator_\n    best_params_per_fold.append(grid_search.best_params_)\n\n    # Evaluate on held-out outer fold\n    y_pred = best_model.predict(X_test_outer)\n    y_pred_proba = best_model.predict_proba(X_test_outer)\n\n    # Calculate metrics\n    acc = accuracy_score(y_test_outer, y_pred)\n    prec = precision_score(y_test_outer, y_pred, average='macro', zero_division=0)\n    rec = recall_score(y_test_outer, y_pred, average='macro', zero_division=0)\n    f1 = f1_score(y_test_outer, y_pred, average='macro', zero_division=0)\n\n    try:\n        roc_auc = roc_auc_score(y_test_outer, y_pred_proba,\n                                multi_class='ovr', average='macro')\n    except:\n        roc_auc = np.nan\n\n    # Store results\n    nested_scores['accuracy'].append(acc)\n    nested_scores['precision'].append(prec)\n    nested_scores['recall'].append(rec)\n    nested_scores['f1'].append(f1)\n    nested_scores['roc_auc'].append(roc_auc)\n\n    fold_time = time.time() - fold_start\n    elapsed = time.time() - start_time\n    remaining = (elapsed / fold_idx) * (10 - fold_idx)\n\n    # Compact parameter display\n    params_str = \", \".join([f\"{k}={v}\" for k, v in list(grid_search.best_params_.items())[:3]])\n    if len(grid_search.best_params_) > 3:\n        params_str += \"...\"\n\n    print(f\"   âœ… Fold {fold_idx:2d}: Acc={acc:.4f} ({acc*100:.2f}%) | Best: {params_str}\")\n    print(f\"   â±ï¸  Fold time: {fold_time:.1f}s | Elapsed: {elapsed/60:.1f}min | Est. remaining: {remaining/60:.1f}min\")\n    print()\n\nelapsed_time = time.time() - start_time\n\nprint()\nprint(\"=\"*80)\nprint(\"ğŸ“Š NESTED CV RESULTS (Unbiased Performance Estimates)\")\nprint(\"=\"*80)\nprint()\nprint(f\"âœ… Completed in {elapsed_time:.1f}s ({elapsed_time/60:.1f} minutes)\")\nprint()\nprint(\"ğŸ¯ Performance Metrics (Mean Â± Std across 10 folds):\")\nprint()\n\n# Calculate and display mean Â± std\nfor metric_name, scores in nested_scores.items():\n    mean_val = np.mean(scores)\n    std_val = np.std(scores)\n    print(f\"   {metric_name.replace('_', ' ').title():15s}: {mean_val:.4f} Â± {std_val:.4f} \"\n          f\"({mean_val*100:.2f}% Â± {std_val*100:.2f}%)\")\n\nprint()\nprint(\"ğŸ“‹ Per-Fold Accuracy Breakdown:\")\nprint(\"   \" + \"-\"*70)\nfor i, acc in enumerate(nested_scores['accuracy'], 1):\n    bar_length = int(acc * 50)\n    bar = 'â–ˆ' * bar_length + 'â–‘' * (50 - bar_length)\n    print(f\"   Fold {i:2d}: {bar} {acc:.4f} ({acc*100:.2f}%)\")\nprint(\"   \" + \"-\"*70)\n\nprint()\nprint(\"âœ… METHODOLOGY VALIDATION:\")\nprint(\"   â€¢ NO data leakage - test folds never seen during hyperparameter tuning\")\nprint(\"   â€¢ Unbiased estimates - each fold tested with hyperparameters tuned on OTHER folds\")\nprint(\"   â€¢ All 406 samples used efficiently - each sample tested exactly once\")\nprint(\"   â€¢ Scientifically rigorous - standard practice for datasets < 1000 samples\")\nprint(\"   â€¢ Class imbalance handled via sample_weight (GBM doesn't support class_weight)\")\nprint()\n\n# Train final model on ALL data with most common best hyperparameters\nprint(f\"ğŸ”§ Training final GBM model on ALL 406 samples...\")\nprint(\"   (Using most common hyperparameters from nested CV)\")\nprint()\n\nfrom collections import Counter\nparam_strings = [str(sorted(p.items())) for p in best_params_per_fold]\nmost_common_params_str = Counter(param_strings).most_common(1)[0][0]\nfinal_best_params = dict(eval(most_common_params_str))\n\nprint(f\"   Most common best params: {final_best_params}\")\nprint()\n\n# Compute sample weights for full dataset\nsample_weights_full = compute_sample_weight(class_weight='balanced', y=y)\n\n# Update the primary model variable with optimized parameters\ngbm_model = GradientBoostingClassifier(\n    random_state=42,\n    **final_best_params\n)\n\n# Train on all data WITH sample weights\nprint(\"   âš™ï¸  Training final model...\")\ngbm_model.fit(X, y, sample_weight=sample_weights_full)\n\nprint(f\"   âœ… Final GBM model trained and ready for analysis\")\nprint()\nprint(\"=\"*80)\n\n# Store nested CV results for later reference\nnested_cv_results = {\n    'mean_scores': {k: np.mean(v) for k, v in nested_scores.items()},\n    'std_scores': {k: np.std(v) for k, v in nested_scores.items()},\n    'fold_scores': nested_scores,\n    'best_params': final_best_params,\n    'all_best_params': best_params_per_fold\n}\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model already updated with optimized parameters in previous cell\nprint(\"\\n\" + \"=\"*80)\nprint(\"âœ“ PRIMARY MODEL READY WITH OPTIMIZED PARAMETERS\")\nprint(\"=\"*80)\n\nprint(\"\\nğŸ“Š Model trained with optimal hyperparameters from Nested CV:\")\nprint(f\"  Model type: {type(gbm_model).__name__}\")\nprint(f\"  Trained on: {X.shape[0]} samples, {X.shape[1]} features\")\nprint(\"\\nğŸ¯ Optimal Hyperparameters:\")\nfor param, value in final_best_params.items():\n    print(f\"  - {param}: {value}\")\n\nprint(\"\\nâœ“ Model ready for predictions and analysis\")\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"=\"*80)\nprint(\"OPTIMIZED GBM CLASSIFIER - FINAL MODEL SUMMARY\")\nprint(\"=\"*80)\n\n# Display the optimized model parameters (from nested CV)\nprint(\"\\nğŸ† OPTIMAL Hyperparameters (from Nested CV):\")\nfor param, value in final_best_params.items():\n    print(f\"  - {param}: {value}\")\n\nprint(\"\\nğŸ“Š Model Performance (from Nested CV):\")\nprint(f\"  - Mean CV Accuracy: {nested_cv_results['mean_scores']['accuracy']:.4f} ({nested_cv_results['mean_scores']['accuracy']*100:.2f}%)\")\nprint(f\"  - Std CV Accuracy:  {nested_cv_results['std_scores']['accuracy']:.4f} (Â±{nested_cv_results['std_scores']['accuracy']*100:.2f}%)\")\nprint(f\"  - Training samples: {X.shape[0]}\")\nprint(f\"  - Feature count: {X.shape[1]}\")\n\nprint(\"\\nğŸ”‘ KEY INSIGHTS:\")\nprint(\"  1. GBM uses gradient boosting (sequential error correction)\")\nprint(\"  2. Each tree learns from previous trees' mistakes\")\nprint(\"  3. Lower learning_rate + more estimators = better generalization\")\nprint(\"  4. Shallow trees (max_depth 3-7) work better than deep trees\")\nprint(\"  5. Subsampling helps prevent overfitting\")\nprint(\"  6. Sample weights handle class imbalance\")\n\nprint(\"\\nâœ“ Model ready for predictions and feature importance analysis!\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 8. Model Evaluation","metadata":{}},{"cell_type":"markdown","source":"---\n\n## 9. Confusion Matrix","metadata":{}},{"cell_type":"markdown","source":"---\n\n## 10. Feature Importance Analysis","metadata":{}},{"cell_type":"code","source":"# FIX: Define feature_names from your training data columns\nfeature_names = X.columns  # or use X.columns\n\n# Extract feature importance (averaged across all trees)\nfeature_importance = pd.DataFrame({\n    'Feature': feature_names,\n    'Importance': gbm_model.feature_importances_\n}).sort_values('Importance', ascending=False)\n\nprint(\"=\"*80)\nprint(\"FEATURE IMPORTANCE (TOP 20)\")\nprint(\"=\"*80)\nprint(\"\\nImportance scores represent the average contribution across all 100 trees.\")\nprint(\"GBM calculates importance via mean decrease in impurity (Gini).\")\nprint(\"\\nTop 20 most important features:\\n\")\nprint(feature_importance.head(20).to_string(index=False))\n\n# Show total importance from top features\ntop_10_importance = feature_importance.head(10)['Importance'].sum()\ntop_20_importance = feature_importance.head(20)['Importance'].sum()\nprint(f\"\\nCumulative importance:\")\nprint(f\"  Top 10 features: {top_10_importance:.4f} ({top_10_importance*100:.2f}%)\")\nprint(f\"  Top 20 features: {top_20_importance:.4f} ({top_20_importance*100:.2f}%)\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# FIX: Define top_features by taking the top 15 from your importance dataframe\ntop_features = feature_importance.head(15)\n\n# Visualize feature importance\nfig, ax = plt.subplots(figsize=(12, 8))\n\n# Use gradient colors\ncolors = plt.cm.viridis(np.linspace(0, 1, len(top_features)))\n\nbars = ax.barh(range(len(top_features)), top_features['Importance'], \n               color=colors, edgecolor='black', linewidth=1)\n\n# Add value labels\nfor i, (bar, importance) in enumerate(zip(bars, top_features['Importance'])):\n    ax.text(importance + 0.002, i, f'{importance:.4f}', \n            va='center', fontweight='bold')\n\nax.set_yticks(range(len(top_features)))\nax.set_yticklabels(top_features['Feature'])\nax.invert_yaxis()\nax.set_xlabel('Importance Score', fontsize=12, fontweight='bold')\nax.set_title('Top 15 Feature Importance Rankings', fontsize=14, fontweight='bold')\nax.grid(axis='x', alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cumulative importance\nfeature_importance_sorted = feature_importance.sort_values('Importance', ascending=False)\nfeature_importance_sorted['Cumulative'] = feature_importance_sorted['Importance'].cumsum()\n\nfig, ax = plt.subplots(figsize=(12, 6))\nax.plot(range(1, len(feature_importance_sorted)+1), \n        feature_importance_sorted['Cumulative'], \n        linewidth=2, color='darkblue')\n\n# Highlight key thresholds\nax.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='50% importance')\nax.axhline(y=0.75, color='orange', linestyle='--', alpha=0.7, label='75% importance')\nax.axhline(y=0.9, color='green', linestyle='--', alpha=0.7, label='90% importance')\n\nax.set_xlabel('Number of Features', fontsize=12, fontweight='bold')\nax.set_ylabel('Cumulative Importance', fontsize=12, fontweight='bold')\nax.set_title('Cumulative Feature Importance', fontsize=14, fontweight='bold')\nax.legend()\nax.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Find how many features needed for 90% importance\nfeatures_for_90 = (feature_importance_sorted['Cumulative'] <= 0.9).sum() + 1\nprint(f\"\\nFeatures needed for 90% cumulative importance: {features_for_90}/{len(feature_importance)}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 11. Evaluation Set (Eval Set) Score\n\nGBM provides an additional validation metric called **Evaluation Set (Eval Set) Score**.\n\nDuring boosting, each tree is trained on ~63% of the data (bootstrap sample). The remaining ~37% (out-of-bag samples) can be used for validation **without needing a separate test set**. This provides an unbiased estimate of model performance.","metadata":{}},{"cell_type":"code","source":"# KAGGLE EDITION: Removed eval_set code (not supported by sklearn GBM)\n# Note: eval_set and evals_result() are XGBoost-specific features\n# sklearn's GradientBoostingClassifier doesn't support these methods\n\nprint(\"=\"*80)\nprint(\"MODEL VALIDATION STRATEGY\")\nprint(\"=\"*80)\n\nprint(\"\\nGBM Validation Approach:\")\nprint(\"  âœ“ Nested CV used for unbiased performance estimation\")\nprint(\"  âœ“ 10-fold outer loop tests model on held-out data\")\nprint(\"  âœ“ 5-fold inner loop optimizes hyperparameters\")\nprint(\"  âœ“ NO data leakage - test folds never seen during tuning\")\nprint(\"  âœ“ Sample weights handle class imbalance\")\n\nprint(f\"\\nğŸ“Š Nested CV Performance Summary:\")\nprint(f\"  - Accuracy:  {nested_cv_results['mean_scores']['accuracy']:.4f} Â± {nested_cv_results['std_scores']['accuracy']:.4f}\")\nprint(f\"  - Precision: {nested_cv_results['mean_scores']['precision']:.4f} Â± {nested_cv_results['std_scores']['precision']:.4f}\")\nprint(f\"  - Recall:    {nested_cv_results['mean_scores']['recall']:.4f} Â± {nested_cv_results['std_scores']['recall']:.4f}\")\nprint(f\"  - F1 Score:  {nested_cv_results['mean_scores']['f1']:.4f} Â± {nested_cv_results['std_scores']['f1']:.4f}\")\n\nprint(\"\\nâœ“ Validation methodology ensures:\")\nprint(\"  â€¢ Unbiased performance estimates\")\nprint(\"  â€¢ No optimistic bias from tuning on test data\")\nprint(\"  â€¢ Scientifically rigorous for small datasets\")\n\nprint(\"\\nâœ“ Validation complete\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 12. Cross-Validation Analysis","metadata":{}},{"cell_type":"code","source":"# âœ… Step 6: Comprehensive Cross-Validation Evaluation\n# KAGGLE EDITION: Fixed to use gbm_model instead of rf_model\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\nimport pandas as pd\nimport numpy as np\n\n# Setup 10-fold Stratified Cross-Validation\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n\n# Define multiple scoring metrics\nscoring = {\n    'accuracy': 'accuracy',\n    'precision': 'precision_weighted',\n    'recall': 'recall_weighted',\n    'f1': 'f1_weighted',\n    'roc_auc': 'roc_auc_ovo'  # One-vs-One for multiclass\n}\n\n# Perform cross-validation with multiple metrics using GBM model\ncv_results = cross_validate(\n    gbm_model, X, y, \n    cv=skf, \n    scoring=scoring,\n    n_jobs=-1,\n    return_train_score=False\n)\n\n# Extract and display per-fold scores\nprint(\"\\n\" + \"=\"*80)\nprint(\"ğŸ“Š CROSS-VALIDATION RESULTS (10-Fold Stratified)\")\nprint(\"=\"*80)\n\nmetrics_data = {}\nfor metric in scoring.keys():\n    fold_scores = cv_results[f'test_{metric}']\n    mean_score = fold_scores.mean()\n    std_score = fold_scores.std()\n    metrics_data[metric] = fold_scores\n    \n    print(f\"\\nğŸ¯ {metric.upper()}:\")\n    print(f\"  Mean: {mean_score:.4f} ({mean_score*100:.2f}%)\")\n    print(f\"  Std:  {std_score:.4f} (Â±{std_score*100:.2f}%)\")\n    print(f\"  95% CI: [{mean_score - 2*std_score:.4f}, {mean_score + 2*std_score:.4f}]\")\n    print(f\"  Per-fold scores:\")\n    \n    for fold_idx, score in enumerate(fold_scores, 1):\n        print(f\"    Fold {fold_idx:2d}: {score:.4f} ({score*100:.2f}%)\")\n\n# Create summary dataframe\ncv_summary = pd.DataFrame(metrics_data)\ncv_summary.index = [f'Fold {i+1}' for i in range(10)]\nprint(f\"\\n{cv_summary.to_string()}\")\n\nprint(f\"\\n{'='*80}\")\nprint(\"ğŸ“ˆ SUMMARY STATISTICS:\")\nprint(f\"{'='*80}\")\nfor metric in scoring.keys():\n    fold_scores = cv_results[f'test_{metric}']\n    print(f\"{metric:12s}: {fold_scores.mean():.4f} Â± {fold_scores.std():.4f}\")\n\n# Visualize per-fold scores\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\nfig.suptitle('10-Fold Cross-Validation Scores - All Metrics (GBM)', fontsize=16, fontweight='bold')\n\nmetric_axes = [\n    (axes[0, 0], 'accuracy'),\n    (axes[0, 1], 'precision'),\n    (axes[1, 0], 'recall'),\n    (axes[1, 1], 'f1')\n]\n\nfor ax, metric in metric_axes:\n    fold_scores = cv_results[f'test_{metric}']\n    mean_score = fold_scores.mean()\n    std_score = fold_scores.std()\n    \n    bars = ax.bar(range(1, 11), fold_scores, color='skyblue', edgecolor='black', linewidth=1.5)\n    ax.axhline(y=mean_score, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_score:.3f}')\n    ax.axhline(y=mean_score + std_score, color='orange', linestyle=':', linewidth=1.5, alpha=0.7)\n    ax.axhline(y=mean_score - std_score, color='orange', linestyle=':', linewidth=1.5, alpha=0.7, label='Â±1 Std')\n    \n    ax.set_xlabel('Fold Number', fontweight='bold')\n    ax.set_ylabel(metric.capitalize(), fontweight='bold')\n    ax.set_title(f'{metric.capitalize()}: {mean_score:.4f} Â± {std_score:.4f}')\n    ax.set_ylim([0, 1])\n    ax.grid(axis='y', alpha=0.3)\n    ax.legend()\n    \n    for i, (bar, score) in enumerate(zip(bars, fold_scores)):\n        height = bar.get_height()\n        ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n                f'{score:.3f}', ha='center', va='bottom', fontsize=9)\n\nplt.tight_layout()\nplt.savefig('cv_results_all_metrics.png', dpi=300, bbox_inches='tight')\nprint(f\"\\nâœ… Saved visualization to: cv_results_all_metrics.png\")\nplt.show()\n\n# Store for later comparison\nprint(f\"\\nâœ… Cross-validation complete!\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 13. Ensemble Analysis","metadata":{}},{"cell_type":"code","source":"# Ensemble Diversity Analysis - Not applicable to GBM\n# GBM uses boosting (sequential) rather than bagging (parallel)\n# Tree diversity is ensured through gradient boosting process\nprint(\"Skipping ensemble diversity - GBM uses boosting, not bagging\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## Summary: Part 1 Complete","metadata":{}},{"cell_type":"markdown","source":"# Part 2: Knowledge-Driven Safer Medication Pathway Recommendation\n\n## Section 3.5.4: Knowledge-Driven Explainability (XAI) Framework\n\n**Integration with GBM:**\n- Part 1: ML model predicts DDI severity (Major/Moderate/Minor)\n- Part 2: XAI framework provides evidence-based clinical context\n- Result: Predictions + Actionable clinical recommendations\n\n**XAI Rules Implemented:**\n- Rule A: ACEI vs ARB Mortality Benefit (Alcocer 2023)\n- Rule B: ACEI Tolerability & Cough Risk (Hu 2023)\n- Rule C: CCB+RAAS Combination Therapy (Makani 2011)\n- Rule D: Diuretic Efficacy - Indapamide vs HCTZ (Roush 2015)\n- Rule E: Beta-Blocker Phenotype Targeting (Mahfoud 2024)","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Load XAI-Enhanced Dataset","metadata":{}},{"cell_type":"code","source":"# Load dataset with XAI Framework (Knowledge-Driven Explainability)\n# KAGGLE EDITION - Updated path\ndf_xai = pd.read_csv('/kaggle/input/fyp-drug-interaction-final/FYP_Drug_Interaction_Final.csv')\n\nprint(\"=\"*80)\nprint(\"KNOWLEDGE-DRIVEN XAI FRAMEWORK DATASET LOADED\")\nprint(\"Section 3.5.4: Knowledge-Driven Explainability (XAI) Framework\")\nprint(\"=\"*80)\nprint(f\"\\nTotal drug pairs: {len(df_xai)}\")\nprint(f\"\\nXAI columns available:\")\nxai_cols = [col for col in df_xai.columns if 'XAI' in col]\nfor col in xai_cols:\n    print(f\"  - {col}\")\n\n# Show XAI rule coverage statistics\nprint(f\"\\n{'='*80}\")\nprint(\"XAI RULE COVERAGE STATISTICS\")\nprint(\"=\"*80)\n\nrule_a_count = (df_xai['XAI_Rule_A_Mortality'] != \"\").sum()\nrule_b_count = (df_xai['XAI_Rule_B_Tolerability'] != \"\").sum()\nrule_c_count = (df_xai['XAI_Rule_C_CCB_RAAS_Combo'] != \"\").sum()\nrule_d_count = (df_xai['XAI_Rule_D_Diuretic'] != \"\").sum()\nrule_e_count = (df_xai['XAI_Rule_E_BetaBlocker'] != \"\").sum()\ntotal_with_notes = (df_xai['XAI_Combined_Clinical_Notes'] != \"No specific XAI rules apply to this combination.\").sum()\n\nprint(f\"\\nRule A (ACEI vs ARB Mortality):     {rule_a_count} pairs ({rule_a_count/len(df_xai)*100:.1f}%)\")\nprint(f\"  Evidence: Alcoer et al. (2023)\")\nprint(f\"  Focus: ACEIs reduce all-cause mortality; ARBs do not\")\n\nprint(f\"\\nRule B (ACEI Tolerability):         {rule_b_count} pairs ({rule_b_count/len(df_xai)*100:.1f}%)\")\nprint(f\"  Evidence: Hu et al. (2023), ACCP Guidelines (2006)\")\nprint(f\"  Focus: ACEIs have 3.2x higher cough risk vs ARBs\")\n\nprint(f\"\\nRule C (CCB+RAAS Combination):      {rule_c_count} pairs ({rule_c_count/len(df_xai)*100:.1f}%)\")\nprint(f\"  Evidence: Makani et al. (2011), De la Sierra (2009)\")\nprint(f\"  Focus: CCB+RAAS reduces peripheral edema by 38%\")\n\nprint(f\"\\nRule D (Diuretic Efficacy):         {rule_d_count} pairs ({rule_d_count/len(df_xai)*100:.1f}%)\")\nprint(f\"  Evidence: Roush et al. (2015), Mishra (2016), Burnier et al. (2019)\")\nprint(f\"  Focus: Indapamide superior to HCTZ for mortality/stroke\")\n\nprint(f\"\\nRule E (Beta-Blocker Phenotype):    {rule_e_count} pairs ({rule_e_count/len(df_xai)*100:.1f}%)\")\nprint(f\"  Evidence: Mahfoud et al. (2024), Mancia et al. (2022)\")\nprint(f\"  Focus: Beta-blockers target high heart rate phenotype\")\n\nprint(f\"\\nTotal pairs with clinical context:  {total_with_notes} pairs ({total_with_notes/len(df_xai)*100:.1f}%)\")\nprint(f\"Pairs without XAI notes:             {len(df_xai) - total_with_notes} pairs ({(len(df_xai) - total_with_notes)/len(df_xai)*100:.1f}%)\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 2: Define Severity-to-Risk Mapping","metadata":{}},{"cell_type":"code","source":"\n# Define severity to risk score mapping (used by model)\nSEVERITY_TO_RISK = {\n    'Major': 0.25,      # Highest risk\n    'Moderate': 0.50,   # Medium risk\n    'Minor': 0.75,      # Lower risk\n    'None': 1.00        # No interaction\n}\n\n# Reverse mapping for display\nRISK_TO_SEVERITY = {v: k for k, v in SEVERITY_TO_RISK.items()}\n\nprint(\"=\"*80)\nprint(\"SEVERITY-TO-RISK MAPPING\")\nprint(\"=\"*80)\nfor severity, score in sorted(SEVERITY_TO_RISK.items(), key=lambda x: x[1]):\n    print(f\"  {severity:12s} â†’ {score:.2f} (lower = higher risk)\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 3: Generate Predictions Using Trained GBM Model","metadata":{}},{"cell_type":"code","source":"\n# Generate predictions for all drug pairs using trained model\nprint(\"=\"*80)\nprint(\"GENERATING PREDICTIONS FOR ALL DRUG PAIRS\")\nprint(\"=\"*80)\n\n# Filter to pairs with Final_Severity (same as training data)\ndf_xai_valid = df_xai[df_xai['Final_Severity'].notna()].copy()\n\nprint(f\"\\nPredicting for {len(df_xai_valid)} drug pairs...\")\n\n# Prepare features (same as training)\nfeatures_xai = ['Drug_A_Name', 'Drug_B_Name', 'Drug_A_Class', 'Drug_B_Class']\nX_all = pd.get_dummies(df_xai_valid[features_xai], drop_first=False)\n\n# Ensure same feature columns as training\nmissing_cols = set(X.columns) - set(X_all.columns)\nfor col in missing_cols:\n    X_all[col] = 0\nX_all = X_all[X.columns]  # Ensure same order\n\n# Generate predictions (works with dt_model, rf_model, or gbm_model)\n# Determine which model to use based on what's available\nif 'dt_model' in globals() or 'dt_model' in locals():\n    model_to_use = dt_model\n    model_name = \"Decision Tree\"\nelif 'rf_model' in globals() or 'rf_model' in locals():\n    model_to_use = rf_model\n    model_name = \"Random Forest\"\nelif 'gbm_model' in globals() or 'gbm_model' in locals():\n    model_to_use = gbm_model\n    model_name = \"GBM\"\nelse:\n    raise ValueError(\"No trained model found! Expected dt_model, rf_model, or gbm_model\")\n\nprint(f\"Using {model_name} model for predictions...\")\n\ny_pred_all = model_to_use.predict(X_all)\npredicted_severities = [target_classes[i] for i in y_pred_all]\n\n# Add predictions to dataframe\ndf_xai_valid['Predicted_Severity'] = predicted_severities\n\n# Convert predictions to risk scores\ndf_xai_valid['Predicted_Risk_Score'] = df_xai_valid['Predicted_Severity'].map(SEVERITY_TO_RISK)\n\nprint(\"âœ“ Predictions complete!\")\n\n# Show prediction distribution\npred_dist = df_xai_valid['Predicted_Severity'].value_counts().sort_index()\nprint(f\"\\nPredicted severity distribution:\")\nfor sev, count in pred_dist.items():\n    print(f\"  {sev:12s}: {count:3d} pairs ({count/len(df_xai_valid)*100:5.1f}%)\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 4: Integrate XAI Clinical Context with Predictions","metadata":{}},{"cell_type":"code","source":"\n# Display XAI clinical context alongside predictions\nprint(\"=\"*80)\nprint(\"INTEGRATING XAI CLINICAL CONTEXT WITH PREDICTIONS\")\nprint(\"Section 3.5.4: Knowledge-Driven Explainability Framework\")\nprint(\"=\"*80)\n\nprint(f\"\\nApproach:\")\nprint(\"  1. ML Model predicts DDI severity (Major/Moderate/Minor)\")\nprint(\"  2. XAI Framework provides evidence-based clinical context\")\nprint(\"  3. Combined output guides safer prescribing decisions\")\n\n# Count predictions by XAI rule applicability\nprint(f\"\\n{'='*80}\")\nprint(\"PREDICTIONS WITH XAI CONTEXT\")\nprint(\"=\"*80)\n\n# Show examples of predictions enhanced with XAI\nprint(f\"\\nExample 1: ACEI + CCB Combination (Rule A, B, C apply)\")\nacei_ccb_example = df_xai_valid[\n    ((df_xai_valid['Drug_A_Class'] == 'ACEI') & (df_xai_valid['Drug_B_Class'] == 'CCB')) |\n    ((df_xai_valid['Drug_A_Class'] == 'CCB') & (df_xai_valid['Drug_B_Class'] == 'ACEI'))\n].head(1)\n\nif not acei_ccb_example.empty:\n    row = acei_ccb_example.iloc[0]\n    print(f\"  Pair: {row['Drug_A_Name']} + {row['Drug_B_Name']}\")\n    print(f\"  Predicted Severity: {row['Predicted_Severity']} (Risk Score: {row['Predicted_Risk_Score']:.2f})\")\n    print(f\"\\n  XAI Clinical Context:\")\n    if row['XAI_Rule_C_CCB_RAAS_Combo']:\n        print(f\"    â€¢ {row['XAI_Rule_C_CCB_RAAS_Combo'][:150]}...\")\n\nprint(f\"\\nExample 2: Diuretic Selection (Rule D applies)\")\nindapamide_example = df_xai_valid[\n    (df_xai_valid['Drug_A_Name'] == 'Indapamide') | (df_xai_valid['Drug_B_Name'] == 'Indapamide')\n].head(1)\n\nif not indapamide_example.empty:\n    row = indapamide_example.iloc[0]\n    print(f\"  Pair: {row['Drug_A_Name']} + {row['Drug_B_Name']}\")\n    print(f\"  Predicted Severity: {row['Predicted_Severity']} (Risk Score: {row['Predicted_Risk_Score']:.2f})\")\n    print(f\"\\n  XAI Clinical Context:\")\n    if row['XAI_Rule_D_Diuretic']:\n        print(f\"    â€¢ {row['XAI_Rule_D_Diuretic'][:150]}...\")\n\n# Statistics on XAI coverage across predictions\nprint(f\"\\n{'='*80}\")\nprint(\"XAI COVERAGE FOR PREDICTED PAIRS\")\nprint(\"=\"*80)\n\nseverity_by_xai = df_xai_valid.groupby('Predicted_Severity').apply(\n    lambda x: (x['XAI_Combined_Clinical_Notes'] != \"No specific XAI rules apply to this combination.\").sum()\n)\n\nprint(f\"\\nPairs with XAI clinical notes by predicted severity:\")\nfor sev, count in severity_by_xai.items():\n    total_sev = (df_xai_valid['Predicted_Severity'] == sev).sum()\n    print(f\"  {sev:12s}: {count}/{total_sev} pairs ({count/total_sev*100:.1f}% with XAI context)\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Clinical Scenario 1: ACEI/ARB + CCB Combination Therapy\n\n**Clinical Question:** For a patient requiring RAAS blocker + CCB combination:\n- Which combination is safest?\n- What's the clinical evidence?","metadata":{}},{"cell_type":"code","source":"\n# Clinical Scenario 1: Patient needs ACEI/ARB + CCB combination therapy\nprint(\"=\"*80)\nprint(\"CLINICAL SCENARIO 1: ACEI/ARB + CCB COMBINATION THERAPY\")\nprint(\"Knowledge-Driven Recommendation (XAI Rules A, B, C)\")\nprint(\"=\"*80)\nprint(\"\\nClinical Context:\")\nprint(\"  Patient requires combination therapy:\")\nprint(\"  - Either ACEI or ARB (for RAAS blockade)\")\nprint(\"  - Plus CCB (for additional BP lowering)\")\nprint(\"\\nQuestion: Which combination is safest AND most effective?\")\n\n# Filter to ACEI+CCB and ARB+CCB combinations\nacei_ccb = df_xai_valid[\n    ((df_xai_valid['Drug_A_Class'] == 'ACEI') & (df_xai_valid['Drug_B_Class'] == 'CCB')) |\n    ((df_xai_valid['Drug_A_Class'] == 'CCB') & (df_xai_valid['Drug_B_Class'] == 'ACEI'))\n].copy()\n\narb_ccb = df_xai_valid[\n    ((df_xai_valid['Drug_A_Class'] == 'ARB') & (df_xai_valid['Drug_B_Class'] == 'CCB')) |\n    ((df_xai_valid['Drug_A_Class'] == 'CCB') & (df_xai_valid['Drug_B_Class'] == 'ARB'))\n].copy()\n\n# Standardize drug pair names for display\ndef format_pair(row):\n    drugs = sorted([row['Drug_A_Name'], row['Drug_B_Name']])\n    return f\"{drugs[0]} + {drugs[1]}\"\n\nacei_ccb['Pair'] = acei_ccb.apply(format_pair, axis=1)\narb_ccb['Pair'] = arb_ccb.apply(format_pair, axis=1)\n\n# Rank by Predicted Risk Score (lower risk = higher score)\nacei_ccb_ranked = acei_ccb.sort_values('Predicted_Risk_Score', ascending=False).head(5)\narb_ccb_ranked = arb_ccb.sort_values('Predicted_Risk_Score', ascending=False).head(5)\n\nprint(f\"\\n{'='*80}\")\nprint(\"TOP 5 ACEI + CCB COMBINATIONS (Ranked by ML Prediction)\")\nprint(\"=\"*80)\nprint(f\"{'Rank':<6} {'Combination':<35} {'Predicted':<12} {'Risk Score':<12}\")\nprint(\"-\" * 65)\nfor rank, (idx, row) in enumerate(acei_ccb_ranked.iterrows(), 1):\n    print(f\"{rank:<6} {row['Pair']:<35} {row['Predicted_Severity']:<12} {row['Predicted_Risk_Score']:<12.2f}\")\n\nprint(f\"\\n{'='*80}\")\nprint(\"TOP 5 ARB + CCB COMBINATIONS (Ranked by ML Prediction)\")\nprint(\"=\"*80)\nprint(f\"{'Rank':<6} {'Combination':<35} {'Predicted':<12} {'Risk Score':<12}\")\nprint(\"-\" * 65)\nfor rank, (idx, row) in enumerate(arb_ccb_ranked.iterrows(), 1):\n    print(f\"{rank:<6} {row['Pair']:<35} {row['Predicted_Severity']:<12} {row['Predicted_Risk_Score']:<12.2f}\")\n\n# Display XAI clinical context\nprint(f\"\\n{'='*80}\")\nprint(\"XAI CLINICAL CONTEXT - WHY ACEI+CCB IS PREFERRED\")\nprint(\"=\"*80)\n\n# Show Rule C (CCB+RAAS combo benefit)\nif not acei_ccb_ranked.empty:\n    sample_acei = acei_ccb_ranked.iloc[0]\n    print(f\"\\n[Rule C - Combination Therapy]\")\n    print(f\"{sample_acei['XAI_Rule_C_CCB_RAAS_Combo']}\")\n\n    print(f\"\\n[Rule A - Mortality Benefit]\")\n    print(f\"{sample_acei['XAI_Rule_A_Mortality'][:250]}...\")\n\n    print(f\"\\n[Rule B - Tolerability]\")\n    print(f\"{sample_acei['XAI_Rule_B_Tolerability'][:250]}...\")\n\nprint(f\"\\n{'='*80}\")\nprint(\"CLINICAL RECOMMENDATION:\")\nprint(\"=\"*80)\nprint(f\"  âœ“ BOTH combinations are effective for BP control\")\nprint(f\"  âœ“ BOTH reduce CCB-induced edema by ~38% (Rule C)\")\nprint(f\"\\n  ACEI + CCB PREFERRED for high-risk patients because:\")\nprint(f\"    â€¢ ACEIs significantly reduce all-cause mortality (Rule A)\")\nprint(f\"    â€¢ Mortality benefit > tolerability concerns\")\nprint(f\"\\n  ARB + CCB alternative when:\")\nprint(f\"    â€¢ Patient has history of ACEI-induced cough\")\nprint(f\"    â€¢ Tolerability is primary concern\")\nprint(f\"\\n  Evidence: Alcocer 2023, Makani 2011, De la Sierra 2009\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Clinical Scenario 2: Diuretic Selection (Indapamide vs HCTZ)\n\n**Clinical Question:** For a patient requiring diuretic therapy:\n- Indapamide or Hydrochlorothiazide?\n- What's the outcome evidence?","metadata":{}},{"cell_type":"code","source":"\n# Clinical Scenario 2: Choosing a diuretic (Indapamide vs HCTZ)\nprint(\"=\"*80)\nprint(\"CLINICAL SCENARIO 2: DIURETIC SELECTION FOR COMBINATION THERAPY\")\nprint(\"Knowledge-Driven Recommendation (XAI Rule D)\")\nprint(\"=\"*80)\nprint(\"\\nClinical Context:\")\nprint(\"  Patient needs RAAS blocker + Diuretic combination\")\nprint(\"\\nQuestion: Indapamide or Hydrochlorothiazide (HCTZ)?\")\n\n# Filter to RAAS + Diuretic combinations\nraas_diuretic = df_xai_valid[\n    (((df_xai_valid['Drug_A_Class'] == 'ACEI') | (df_xai_valid['Drug_A_Class'] == 'ARB')) &\n     (df_xai_valid['Drug_B_Class'] == 'Diuretic')) |\n    (((df_xai_valid['Drug_B_Class'] == 'ACEI') | (df_xai_valid['Drug_B_Class'] == 'ARB')) &\n     (df_xai_valid['Drug_A_Class'] == 'Diuretic'))\n].copy()\n\nraas_diuretic['Pair'] = raas_diuretic.apply(format_pair, axis=1)\n\n# Separate Indapamide and HCTZ pairs\nindapamide_pairs = raas_diuretic[raas_diuretic['Pair'].str.contains('Indapamide')]\nhctz_pairs = raas_diuretic[raas_diuretic['Pair'].str.contains('Hydrochlorothiazide')]\n\nprint(f\"\\n{'='*80}\")\nprint(\"RAAS BLOCKER + INDAPAMIDE COMBINATIONS\")\nprint(\"=\"*80)\nif len(indapamide_pairs) > 0:\n    indapamide_ranked = indapamide_pairs.sort_values('Predicted_Risk_Score', ascending=False)\n    print(f\"{'Combination':<40} {'Predicted':<12} {'Risk Score':<12}\")\n    print(\"-\" * 64)\n    for idx, row in indapamide_ranked.iterrows():\n        print(f\"{row['Pair']:<40} {row['Predicted_Severity']:<12} {row['Predicted_Risk_Score']:<12.2f}\")\n\nprint(f\"\\n{'='*80}\")\nprint(\"RAAS BLOCKER + HCTZ COMBINATIONS\")\nprint(\"=\"*80)\nif len(hctz_pairs) > 0:\n    hctz_ranked = hctz_pairs.sort_values('Predicted_Risk_Score', ascending=False)\n    print(f\"{'Combination':<40} {'Predicted':<12} {'Risk Score':<12}\")\n    print(\"-\" * 64)\n    for idx, row in hctz_ranked.iterrows():\n        print(f\"{row['Pair']:<40} {row['Predicted_Severity']:<12} {row['Predicted_Risk_Score']:<12.2f}\")\n\n# Display XAI clinical context\nprint(f\"\\n{'='*80}\")\nprint(\"XAI CLINICAL CONTEXT - WHY INDAPAMIDE IS PREFERRED\")\nprint(\"=\"*80)\n\nif len(indapamide_pairs) > 0:\n    sample_indap = indapamide_ranked.iloc[0]\n    print(f\"\\n[Rule D - Diuretic Efficacy]\")\n    print(f\"{sample_indap['XAI_Rule_D_Diuretic']}\")\n\nif len(indapamide_pairs) > 0 and len(hctz_pairs) > 0:\n    avg_indap = indapamide_ranked['Predicted_Risk_Score'].mean()\n    avg_hctz = hctz_ranked['Predicted_Risk_Score'].mean()\n    diff = avg_indap - avg_hctz\n\n    print(f\"\\n{'='*80}\")\n    print(\"CLINICAL RECOMMENDATION:\")\n    print(\"=\"*80)\n    print(f\"  Average Indapamide risk score: {avg_indap:.2f}\")\n    print(f\"  Average HCTZ risk score:        {avg_hctz:.2f}\")\n    print(f\"  Difference:                     {diff:+.2f}\")\n    print(f\"\\n  INDAPAMIDE STRONGLY PREFERRED due to:\")\n    print(f\"    âœ“ Significantly reduces all-cause mortality, stroke, heart failure\")\n    print(f\"    âœ“ HCTZ fails to demonstrate these cardiovascular benefits\")\n    print(f\"    âœ“ ~50% more potent with superior 24-hour BP control\")\n    print(f\"\\n  Evidence: Roush et al. 2015, Mishra 2016, Burnier et al. 2019\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Clinical Scenario 3: Beta-Blocker Phenotype Targeting\n\n**Clinical Question:** For a patient with high resting heart rate (>80 bpm):\n- Are beta-blockers indicated?\n- What's the phenotype-based rationale?","metadata":{}},{"cell_type":"code","source":"\n# Clinical Scenario 3: Beta-Blocker for High Heart Rate Phenotype\nprint(\"=\"*80)\nprint(\"CLINICAL SCENARIO 3: BETA-BLOCKER PHENOTYPE TARGETING\")\nprint(\"Knowledge-Driven Recommendation (XAI Rule E)\")\nprint(\"=\"*80)\nprint(\"\\nClinical Context:\")\nprint(\"  Patient has hypertension with HIGH RESTING HEART RATE (>80 bpm)\")\nprint(\"\\nQuestion: Which drug class combination includes Beta-Blocker?\")\n\n# Filter to Beta-Blocker combinations\nbb_combos = df_xai_valid[\n    (df_xai_valid['Drug_A_Class'] == 'Beta-Blocker') |\n    (df_xai_valid['Drug_B_Class'] == 'Beta-Blocker')\n].copy()\n\nbb_combos['Pair'] = bb_combos.apply(format_pair, axis=1)\n\n# Get Beta-Blocker + RAAS combinations (most common)\nbb_raas = bb_combos[\n    ((bb_combos['Drug_A_Class'].isin(['ACEI', 'ARB'])) |\n     (bb_combos['Drug_B_Class'].isin(['ACEI', 'ARB'])))\n].copy()\n\nprint(f\"\\n{'='*80}\")\nprint(\"TOP BETA-BLOCKER + RAAS BLOCKER COMBINATIONS\")\nprint(\"=\"*80)\nif len(bb_raas) > 0:\n    bb_raas_ranked = bb_raas.sort_values('Predicted_Risk_Score', ascending=False).head(10)\n    print(f\"{'Combination':<40} {'Predicted':<12} {'Risk Score':<12}\")\n    print(\"-\" * 64)\n    for idx, row in bb_raas_ranked.iterrows():\n        print(f\"{row['Pair']:<40} {row['Predicted_Severity']:<12} {row['Predicted_Risk_Score']:<12.2f}\")\n\n# Display XAI clinical context\nprint(f\"\\n{'='*80}\")\nprint(\"XAI CLINICAL CONTEXT - BETA-BLOCKER PHENOTYPE TARGETING\")\nprint(\"=\"*80)\n\nif len(bb_raas) > 0:\n    sample_bb = bb_raas_ranked.iloc[0]\n    print(f\"\\n[Rule E - Beta-Blocker Phenotype]\")\n    print(f\"{sample_bb['XAI_Rule_E_BetaBlocker']}\")\n\nprint(f\"\\n{'='*80}\")\nprint(\"CLINICAL RECOMMENDATION:\")\nprint(\"=\"*80)\nprint(f\"  Beta-Blockers are APPROPRIATE for:\")\nprint(f\"    âœ“ Patients with fast resting heart rate (>80 bpm)\")\nprint(f\"    âœ“ Sympathetic overactivity (stress-driven hypertension)\")\nprint(f\"    âœ“ Comorbidities: anxiety, migraines, arrhythmias\")\nprint(f\"\\n  NOT first-line for:\")\nprint(f\"    â€¢ Patients with normal/low heart rate\")\nprint(f\"    â€¢ Metabolic syndrome or diabetes risk\")\nprint(f\"\\n  Evidence: ESH 2023 Guidelines, Mahfoud et al. 2024, Mancia et al. 2022\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualization: Predictions with XAI Coverage\n\nVisualize how XAI clinical context enhances ML predictions across drug class combinations.","metadata":{}},{"cell_type":"code","source":"\n# Visualize predictions with XAI clinical context coverage\nprint(\"=\"*80)\nprint(\"VISUALIZING PREDICTIONS WITH XAI CLINICAL CONTEXT\")\nprint(\"=\"*80)\n\n# Create class combination labels\ndef get_class_combo(row):\n    classes = sorted([row['Drug_A_Class'], row['Drug_B_Class']])\n    return f\"{classes[0]} + {classes[1]}\"\n\ndf_xai_valid['Class_Combo'] = df_xai_valid.apply(get_class_combo, axis=1)\n\n# Calculate average risk score by class combination\ncombo_scores = df_xai_valid.groupby('Class_Combo').agg({\n    'Predicted_Risk_Score': ['mean', 'std', 'count']\n}).reset_index()\ncombo_scores.columns = ['Class_Combo', 'Mean_Risk_Score', 'Std_Risk_Score', 'Count']\ncombo_scores = combo_scores.sort_values('Mean_Risk_Score', ascending=False)\n\n# Calculate XAI coverage by class combination\nxai_coverage = df_xai_valid.groupby('Class_Combo').apply(\n    lambda x: (x['XAI_Combined_Clinical_Notes'] != \"No specific XAI rules apply to this combination.\").sum() / len(x) * 100\n).reset_index()\nxai_coverage.columns = ['Class_Combo', 'XAI_Coverage_Pct']\n\n# Merge\ncombo_scores = combo_scores.merge(xai_coverage, on='Class_Combo')\n\n# Plot\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# Bar plot of mean risk scores\ncolors = ['#2ecc71' if cov > 90 else '#3498db' if cov > 50 else '#95a5a6'\n          for cov in combo_scores['XAI_Coverage_Pct']]\n\nbars = ax1.barh(combo_scores['Class_Combo'], combo_scores['Mean_Risk_Score'],\n                color=colors, edgecolor='black', linewidth=1.5)\n\nfor bar, (idx, row) in zip(bars, combo_scores.iterrows()):\n    ax1.text(row['Mean_Risk_Score'] + 0.01, bar.get_y() + bar.get_height()/2,\n             f\"{row['Mean_Risk_Score']:.3f}\\n(n={int(row['Count'])})\\n{row['XAI_Coverage_Pct']:.0f}% XAI\",\n             va='center', fontweight='bold', fontsize=8)\n\nax1.set_xlabel('Average Risk Score (Higher = Safer)', fontsize=12, fontweight='bold')\nax1.set_title('Average Risk Score by Drug Class Combination\\n(Color = XAI Coverage)', fontsize=14, fontweight='bold')\nax1.grid(axis='x', alpha=0.3)\nax1.set_xlim(0, 1.1)\n\n# XAI coverage bar plot\nax2.barh(combo_scores['Class_Combo'], combo_scores['XAI_Coverage_Pct'],\n         color=colors, edgecolor='black', linewidth=1.5)\n\nfor idx, row in combo_scores.iterrows():\n    ax2.text(row['XAI_Coverage_Pct'] + 2, idx,\n             f\"{row['XAI_Coverage_Pct']:.0f}%\",\n             va='center', fontweight='bold', fontsize=9)\n\nax2.set_xlabel('XAI Clinical Context Coverage (%)', fontsize=12, fontweight='bold')\nax2.set_title('Percentage of Pairs with XAI Clinical Notes', fontsize=14, fontweight='bold')\nax2.grid(axis='x', alpha=0.3)\nax2.set_xlim(0, 110)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nâœ“ Visualization complete!\")\nprint(f\"\\nColor Legend:\")\nprint(f\"  Green: >90% XAI coverage (excellent clinical context)\")\nprint(f\"  Blue: 50-90% XAI coverage (good clinical context)\")\nprint(f\"  Gray: <50% XAI coverage (limited clinical context)\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Part 2 Summary: Knowledge-Driven Clinical Decision Support","metadata":{}},{"cell_type":"code","source":"\nprint(\"=\"*80)\nprint(\"PART 2 SUMMARY: KNOWLEDGE-DRIVEN SAFER MEDICATION PATHWAY\")\nprint(\"Section 3.5.4: Knowledge-Driven Explainability (XAI) Framework\")\nprint(\"=\"*80)\n\n# Determine which model was used\nif 'dt_model' in globals() or 'dt_model' in locals():\n    model_name = \"Decision Tree\"\n    model_accuracy = nested_cv_results['mean_scores']['accuracy']  # from Part 1\nelif 'rf_model' in globals() or 'rf_model' in locals():\n    model_name = \"Random Forest\"\n    model_accuracy = nested_cv_results['mean_scores']['accuracy']\nelif 'gbm_model' in globals() or 'gbm_model' in locals():\n    model_name = \"GBM\"\n    model_accuracy = nested_cv_results['mean_scores']['accuracy']\nelse:\n    model_name = \"Unknown\"\n    model_accuracy = 0.0\n\nsummary_text = f\"\"\"\nARCHITECTURE IMPLEMENTED (Section 3.5.4):\n  1. âœ“ ML Prediction: {model_name} predicts DDI severity ({model_accuracy*100:.2f}% accuracy)\n  2. âœ“ XAI Framework: Knowledge-driven clinical context from literature\n  3. âœ“ Integrated Output: Predictions + Evidence-based explanations\n\nKNOWLEDGE-DRIVEN XAI RULES IMPLEMENTED:\n  â€¢ Rule A: ACEI vs ARB Mortality Benefit (Alcocer et al. 2023)\n      â†’ ACEIs reduce all-cause mortality; ARBs do not\n      â†’ Coverage: {rule_a_count} pairs ({rule_a_count/len(df_xai)*100:.1f}%)\n\n  â€¢ Rule B: ACEI Tolerability & Adherence (Hu et al. 2023)\n      â†’ ACEIs have 3.2x higher cough risk vs ARBs\n      â†’ Coverage: {rule_b_count} pairs ({rule_b_count/len(df_xai)*100:.1f}%)\n\n  â€¢ Rule C: CCB+RAAS Combination Therapy (Makani et al. 2011)\n      â†’ Reduces peripheral edema by 38%; improves adherence by 62%\n      â†’ Coverage: {rule_c_count} pairs ({rule_c_count/len(df_xai)*100:.1f}%)\n\n  â€¢ Rule D: Diuretic Efficacy Optimization (Roush et al. 2015)\n      â†’ Indapamide superior to HCTZ for mortality/stroke/HF\n      â†’ Coverage: {rule_d_count} pairs ({rule_d_count/len(df_xai)*100:.1f}%)\n\n  â€¢ Rule E: Beta-Blocker Phenotype Targeting (Mahfoud et al. 2024)\n      â†’ Indicated for high heart rate phenotype (>80 bpm)\n      â†’ Coverage: {rule_e_count} pairs ({rule_e_count/len(df_xai)*100:.1f}%)\n\nPREDICTIONS GENERATED:\n  â€¢ Total combinations analyzed: {len(df_xai_valid)}\n  â€¢ Pairs with XAI clinical context: {total_with_notes} ({total_with_notes/len(df_xai)*100:.1f}%)\n  â€¢ Pairs without XAI context: {len(df_xai) - total_with_notes} ({(len(df_xai) - total_with_notes)/len(df_xai)*100:.1f}%)\n\nCLINICAL SCENARIOS ANALYZED:\n  1. âœ“ ACEI+CCB vs ARB+CCB combinations (Rules A, B, C)\n  2. âœ“ Indapamide vs HCTZ for diuretic selection (Rule D)\n  3. âœ“ Beta-Blocker for high heart rate phenotype (Rule E)\n\nKEY FINDINGS:\n  â€¢ ML predictions provide probabilistic severity classification\n  â€¢ XAI Framework adds clinical context that ML cannot capture\n  â€¢ ACEI+CCB preferred for high-risk patients (mortality benefit)\n  â€¢ Indapamide superior to HCTZ (cardiovascular outcomes)\n  â€¢ Beta-Blockers appropriate for sympathetic overactivity phenotype\n  â€¢ System explains WHY certain combinations are preferred\n\nADVANTAGES OVER NUMERIC SCORING:\n  â€¢ Transparent: Explicit literature citations\n  â€¢ Interpretable: Clinician-readable explanations\n  â€¢ Evidence-based: Grounded in peer-reviewed meta-analyses\n  â€¢ Actionable: Specific recommendations with clinical rationale\n  â€¢ Adaptable: Easy to add new rules as evidence emerges\n\nNEXT STEPS:\n  â€¢ Clinical validation with Dr. Nurulhuda Abdul Manaf (collaborator)\n  â€¢ Align with Malaysian CPG for Hypertension (2018)\n  â€¢ Integrate XAI notes into clinical decision support interface\n  â€¢ Expand rules to cover additional drug classes and scenarios\n\"\"\"\n\nprint(summary_text)\nprint(\"=\"*80)\nprint(\"âœ“ PART 2 COMPLETE!\")\nprint(\"=\"*80)","metadata":{},"outputs":[],"execution_count":null}]}